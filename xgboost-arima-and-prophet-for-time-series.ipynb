{"cells":[{"metadata":{"_uuid":"08bca7d0b90cffc1c40e0cd43e6cd8c1a190f516"},"cell_type":"markdown","source":"# Introduction and Exploration of Algorithms, Suitable for Electrical Energy Cunsumption Time Series Forcasting\n\n## Abstract\n\nA very basic understanding of the subject is expected. The goal of this notebook is to familiarize the reader with the interesting capabilities of three machine learning algorithms in a not overwhelming way. The chosen algorithms diferenciate conceptually from each other and in their performance and will help to broaden one's perspective on the subject. The algorithms are ARIMA and Prophet, spechialized in forecasting  time series, and XGBoost - an ensemble of algorithms:\n\n### 1. ARIMA\n\nAutoRegressive Integrated Moving Average with eXogenous regressors model. Just remember that it is composed of several statistical models and is highly configurable.\n\nARIMA has an **order=(p,d,q)** parameter that manages the AR and MA parts of the algorithm. [\\[statsmodels.tsa.arima_model.ARIMA\\](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARIMA.html?highlight=arima)\n    \nSARIMAX is an extension of ARIMA that enables **seasonal_order(P,D,Q,s)** allowing for day, week, ... components.  [\\[statsmodels.tsa.arima_model.SARIMAX\\]](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)\n    \nThe practice is to run this algorithm for one unknown future date and use that date in the forcasting of next unknown dates.\n    \n### 2. Prophet\n\nProcedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It is released by Facebookâ€™s Core Data Science team.\n\nAdditive model is a model like:\n$$Data = seasonal\\space effect + trend + residual$$\nand, multiplicative model:\n$$Data = seasonal\\space effect * trend * residual$$\n\nThe algorithm provides useful statistics that help visualize the tuning process, e.g. trend, week trend, year trend and their max and min errors. \n\n### 3. XGBoost\n\neXtreme Gradient Boosting.\n\nThe algorithm XGBoost implements is called *gradient boosting decision tree algorithm*. Boosting is an ensemble technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made.\n\nGradient boosting: approach where new models are created that predict the residuals or errors of prior models and then added together to make the final prediction. \n\nTo minimize the loss when adding new modelsgradient descent algorithm is used.\n\nComputational speed and model performance are impressive.\n\n### Data\n\nThe data on which the algorithms will be trained and tested upon comes from Kaggle Hourly Energy Consumption database. It is collected by PJM Interconnection, a company  coordinating the continuous buying, selling, and delivery of wholesale electricity through the Energy Market from suppliers to customers in the reagon of South Carolina, USA. All .csv files contains rows with a timestamp and a value. The name of the value column corresponds to the name of the contractor. the timestamp represents a single hour and the value represents the total energy, cunsumed during that hour."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n\nplt.style.use('fivethirtyeight')\nprint(os.listdir(\"../input\"))\n\nimport statsmodels.api as sm\nfrom fbprophet import Prophet\nimport xgboost as xgb\n\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bde86b4cbb48c08c6b8a5d87b34f955a05aaec07"},"cell_type":"code","source":"def split_data(data, split_date):\n    return data[data.index <= split_date].copy(), \\\n           data[data.index >  split_date].copy()\n\ndef limit(data, frm, to):\n    return data[(data.index>=frm)&(data.index<to)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b04a2c68d76146486fff7f9165a25d1dd5ed727"},"cell_type":"code","source":"energy_hourly = pd.read_csv('../input/PJME_hourly.csv', \n                            index_col=[0], parse_dates=[0])\nenergy_hourly.sort_index(inplace=True)\n\nt = energy_hourly.PJME_MW.copy()\nt = t.drop(t.index[t.index.duplicated()])\nfreq_index = pd.date_range(start=t.index[0], end=t.index[-1], freq='H')\nconstructed = pd.Series(index=freq_index, name='PJME_MW')\nconstructed.update(t)\nconstructed.interpolate(inplace=True)\ntrain, test = split_data(constructed, '01-Jul-2002')\n\ntrain = limit(constructed, '03-01-2011', '04-01-2011')\ntest  = limit(constructed, '04-01-2011', '05-01-2011')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"892d53037515da6e95887cd34993976ac2a80b83"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6039dec1892ac4d10534de2eeeb026b4e7c0bcbe"},"cell_type":"markdown","source":" ## ARIMA\n \nAkaike Information Criterion(AIC) - an estimator of the relative quality of statistical models for a given set of data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"model_A = sm.tsa.statespace.SARIMAX(constructed,\n                                order=(1,1,1),\n                                seasonal_order=(0,0,1,12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults_A = model_A.fit()\nprint('AIC =', results_A.aic) #AIC\n#result_ARIMA = results.forecast(steps=test.shape[0])\nforecast_A = results_A.forecast(steps=test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b54d349b7d2f00c5970bf32b33580a2550c827a"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"a60029f08dbb2545f350b284761227e922c0a364"},"cell_type":"code","source":"model_P = Prophet(interval_width=0.95)\nmodel_P.fit(pd.DataFrame({'ds': train.index, 'y':train}))\nfuture_dates = model_P.make_future_dataframe(periods=test.shape[0], freq='H')\nresults_P = model_P.predict(future_dates[train.shape[0]:])\nforecast_P = results_P.set_index('ds').yhat\n#model_P.make_seasonality_features(period=24*7)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0648fcfeecbf446bf38af1cdf737dfdc4c48429a"},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true,"_uuid":"0d8cbdd4baac059077269e2ce1183a7ab115ce17"},"cell_type":"code","source":"def to_X(data):\n    return pd.Series(data.index).apply(\n        lambda x: (x - data.index[0]).components.hours) \\\n                                .values \\\n                                .reshape(-1,1)\n\nmodel_X = xgb.XGBRegressor(n_estimators=30)\nmodel_X.fit(to_X(train), train.values,\n        eval_set=[(to_X(train), train.values), (to_X(test), test.values)],\n        early_stopping_rounds=50, #stop if 50 consequent rounds without decrease of error\n        verbose=False) # Change verbose to True if you want to see it train\n\nforecast_X = model_X.predict(to_X(test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3620f0170d86f8ff572f9551b2c9641eac8826dc"},"cell_type":"markdown","source":"## Compare the forecasts"},{"metadata":{"trusted":true,"_uuid":"77a2172fec4c36a8ef6e78726fa7aa112ae7ede0"},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.plot(pd.concat([train,test]))\nplt.plot(test.index, forecast_A, label='ARIMA')\nplt.plot(test.index, forecast_P, label='Prophet')\nplt.plot(test.index, forecast_X, label='XGBoost')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"947417b7f7a9ba117acdcda6912e65375e89e4cd"},"cell_type":"code","source":"mean_absolute_error(test, forecast_A), \\\nmean_absolute_error(test, forecast_P), \\\nmean_absolute_error(test, forecast_X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad11111b0b7c8784bfc9a391ccb5305ba7651886"},"cell_type":"markdown","source":"## Conclusion\n\nARIMA is good for guessing the next future value.\n\nProphet is good for captioring seasons - in our case day and week.\n\nXGBoost is good for estimating the most probable behavior of the curve.\n\nTo proceed further in understanding time series forecasting, one has to learn more about algorithm finetuning. A better understanding of algorithms and statistical tools is required. To forecast for a whole month with only a month to learn from in advance is a very small case of possibilities - perhaps if you give more data to Prophet it will capture the trend better. Or, why don't we use multiple algorithms and rate their performance for every prediction. Then we can trust them accordingly based on some other, higher level model. The universe of data science is vast and all you need is desire to understand it."},{"metadata":{"trusted":true,"_uuid":"950ec17b2be5878f27163c2e54a7cf97dcb8087e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}